{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SeungGyu\\anaconda3\\envs\\MatchingNet\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm import trange\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataset_utility import raven_tsne, ToTensor\n",
    "from model.RANet_attmap import RANet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "    model_name = 'RANet',\n",
    "    batch_size = 32,\n",
    "    root = '../dataset/',\n",
    "    dataset = 'IRAVEN',\n",
    "    fig_type = 'distribute_nine',\n",
    "    img_size = 160,\n",
    "    workers = 4,\n",
    "    save = './results/checkpoint/',\n",
    "    train_mode = 0,\n",
    "    train_once = False,\n",
    "    seed = 12345,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.fig_type == 'all':\n",
    "    args.train_once = True\n",
    "else:\n",
    "    args.train_once = False\n",
    "\n",
    "if args.dataset == 'PGM':\n",
    "    args.train_once = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'device: {device}')\n",
    "# torch.manual_seed(args.seed)\n",
    "# if torch.cuda.is_available:\n",
    "#     torch.cuda.manual_seed(args.seed)\n",
    "# np.random.seed(args.seed)\n",
    "# random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RANett(\n",
       "  (scattering): Scattering()\n",
       "  (conv): CNNModule(\n",
       "    (features): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (attention): ChangeAtt(\n",
       "    (embed): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): LayerNorm((32, 20, 20), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (attribute_network): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=8, bias=True)\n",
       "  )\n",
       "  (ff_attribute): FeedForwardResidualBlock(\n",
       "    (_projection): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=8, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=8, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (relation_network): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=32, out_features=5, bias=True)\n",
       "  )\n",
       "  (ff_relation): FeedForwardResidualBlock(\n",
       "    (_projection): Sequential(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=40, out_features=160, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RANet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = args.model_name + '_' + args.dataset + '_' + args.fig_type\n",
    "\n",
    "save_path_model = os.path.join(args.save, save_name)\n",
    "\n",
    "tf = transforms.Compose([ToTensor()])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length 6000 distribute_nine\n",
      "test length 2000 distribute_nine\n"
     ]
    }
   ],
   "source": [
    "train_set = raven_tsne(os.path.join(args.root, args.dataset), 'train', args.fig_type, args.img_size, tf)\n",
    "\n",
    "test_set = raven_tsne(os.path.join(args.root, args.dataset), 'test', args.fig_type, args.img_size, tf)\n",
    "\n",
    "print('train length', len(train_set), args.fig_type)\n",
    "print('test length', len(test_set), args.fig_type)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transparent_cmap(cmap, N=255):\n",
    "    \"Copy colormap and set alpha values\"\n",
    "\n",
    "    mycmap = cmap\n",
    "    mycmap._init()\n",
    "    mycmap._lut[:,-1] = np.linspace(0, 0.8, N+4)\n",
    "    return mycmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(rows):\n",
    "    batch_size, n_rows, n_panels, _, panel_h, panel_w = rows.shape\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        fig, axs = plt.subplots(n_rows, n_panels, figsize=(6,14))\n",
    "\n",
    "        for j in range(n_rows):\n",
    "            for k in range(n_panels):\n",
    "                img = rows[i,j,k].squeeze().cpu().numpy()\n",
    "\n",
    "                axs[j, k].imshow(img, cmap='gray', aspect='auto')\n",
    "                axs[j, k].axis('off')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(rows, att_maps):\n",
    "    batch_size, n_rows, n_panels, _, panel_h, panel_w = rows.shape\n",
    "    _, _, _, _, att_h, att_w = att_maps.shape\n",
    "\n",
    "    cmap = plt.cm.Reds\n",
    "    t_cmap = transparent_cmap(cmap)\n",
    "    #print(att_maps[0][0][0][0])\n",
    "    for i in range(batch_size):\n",
    "        fig, axs = plt.subplots(n_rows, n_panels, figsize=(6, 14))  # Adjusted subplot arrangement\n",
    "        #print(att_maps.shape)\n",
    "        for j in range(n_rows):\n",
    "            for k in range(n_panels):\n",
    "                img = rows[i, j, k].squeeze().cpu().numpy()\n",
    "                att_map = att_maps[i, j, k].squeeze().cpu().numpy()\n",
    "                att_map_resized = cv2.resize(att_map, (panel_h, panel_w), interpolation=cv2.INTER_NEAREST)\n",
    "                att_map_resized = att_map_resized / float(att_map_resized.sum())\n",
    "                \n",
    "                axs[j, k].imshow(img, cmap='gray', aspect='auto')\n",
    "                axs[j, k].imshow(att_map_resized, cmap=t_cmap, alpha=0.5, aspect='auto')  # overlay attention map\n",
    "                axs[j, k].axis('off')\n",
    "\n",
    "                if j>=2:\n",
    "                    axs[j, k].text(panel_w, panel_h, str(j-2), verticalalignment='bottom', horizontalalignment='right', color='black', fontsize=15)\n",
    "            \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rows(questions, answers):\n",
    "    row1 = questions[:,:3].unsqueeze(1)\n",
    "    row2 = questions[:,3:6].unsqueeze(1)\n",
    "    row3_p = questions[:,6:8].unsqueeze(1).repeat(1,8,1,1,1,1)\n",
    "\n",
    "    candidates = answers.unsqueeze(2)\n",
    "    row3 = torch.cat([row3_p, candidates], dim=2)\n",
    "    rows = torch.cat([row1,row2,row3], dim=1)\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_to_rule(meta_matrix):\n",
    "    relations = [\"Constant\", \"Progression\", \"Arithmetic\", \"Distribute_Three\"]\n",
    "    attributes = [\"Number\", \"Position\", \"Type\", \"Size\", \"Color\"]\n",
    "    #print(meta_matrix)\n",
    "    for row in meta_matrix:\n",
    "        rule = []\n",
    "        for i, value in enumerate(row):\n",
    "            if value == 1:\n",
    "                if i < 4:  # relation\n",
    "                    rule.append(relations[i])\n",
    "                else:  # attribute\n",
    "                    rule.append(attributes[i-4])\n",
    "        if rule:  # if rule is not empty\n",
    "            print(\" \".join(rule))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(fig, filename):\n",
    "    fig.savefig(filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_rows(rows, model):\n",
    "    rows = rows.squeeze().cpu().numpy()\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
    "    for j in range(3):\n",
    "        axs[j].imshow(rows[0, j], cmap='gray')\n",
    "        axs[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_image(fig, 'rows_'+str(model)+'.png')\n",
    "\n",
    "def plot_feat_map(feat_map, model):\n",
    "    feat_map = feat_map.squeeze().cpu().numpy()\n",
    "    fig, axs = plt.subplots(32, 3, figsize=(9, 100))\n",
    "    for j in range(3):\n",
    "        for k in range(32):\n",
    "            resized_feat_map = cv2.resize(feat_map[0, j, k], (160, 160), interpolation=cv2.INTER_NEAREST)\n",
    "            axs[k, j].imshow(resized_feat_map, cmap='gray')\n",
    "            axs[k, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_image(fig, 'feat_map_'+str(model)+'.png')\n",
    "\n",
    "def plot_att_map(att_map, model):\n",
    "    att_map = att_map.squeeze().cpu().numpy()\n",
    "    fig, axs = plt.subplots(32, 3, figsize=(9, 100))\n",
    "    for j in range(3):\n",
    "        for k in range(32):\n",
    "            resized_att_map = cv2.resize(att_map[0, j, k], (160, 160), interpolation=cv2.INTER_NEAREST)\n",
    "            axs[k, j].imshow(resized_att_map, cmap='gray')\n",
    "            axs[k, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_image(fig, 'att_map_'+str(model)+'.png')\n",
    "\n",
    "def plot_aug_feat(aug_feat, model):\n",
    "    aug_feat = aug_feat.squeeze().cpu().numpy()\n",
    "    fig, axs = plt.subplots(32, 3, figsize=(9, 100))\n",
    "    for j in range(3):\n",
    "        for k in range(32):\n",
    "            resized_aug_feat = cv2.resize(aug_feat[0, j, k], (160, 160), interpolation=cv2.INTER_NEAREST)\n",
    "            axs[k, j].imshow(resized_aug_feat, cmap='gray')\n",
    "            axs[k, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_image(fig, 'aug_feat_'+str(model)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression Number\n",
      "Distribute_Three Type\n",
      "Distribute_Three Size\n",
      "Arithmetic Color\n",
      "Att target: tensor([6]), predict: tensor([6])\n",
      "No Att target: tensor([6]), predict: tensor([6])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model.load_state_dict(torch.load('./model.pth'))\n",
    "    model.eval()\n",
    "    data_i = []\n",
    "    for i in range(10):\n",
    "        number = random.randint(0,1999)\n",
    "        data_i.append(i)\n",
    "\n",
    "    for i in data_i:\n",
    "        sample_data = test_set[i]\n",
    "        \n",
    "        image, target, meta_target, meta_matrix = sample_data\n",
    "\n",
    "        image = image.to(device).unsqueeze(0)\n",
    "        target = target.to(device).unsqueeze(0)\n",
    "\n",
    "        questions = image[:,:8]\n",
    "        answers = image[:,8:]\n",
    "\n",
    "        questions = torch.unsqueeze(questions, dim=2)\n",
    "        answers = torch.unsqueeze(answers, dim=2)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predict, att_maps, feat_maps, aug_feat = model(image)\n",
    "        pred = torch.max(predict, 1)[1]\n",
    "        meta_to_rule(meta_matrix)\n",
    "        \n",
    "        print(f'Att target: {target.cpu()}, predict: {pred.cpu()}')\n",
    "        rows = make_rows(questions, answers)\n",
    "        \n",
    "        plot_rows(rows, '6e-5')\n",
    "        plot_feat_map(feat_maps, '6e-5')\n",
    "        plot_att_map(att_maps, '6e-5')\n",
    "        plot_aug_feat(aug_feat, '6e-5')\n",
    "        \n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MatchingNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
